{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475f2966",
   "metadata": {},
   "source": [
    "# Ingest√£o Bronze - Controle Ativo\n",
    "\n",
    "Este notebook realiza a leitura de um arquivo CSV contendo o controle de A√ß√µes e FII\n",
    "e grava os dados em formato Delta na camada **Bronze**.\n",
    "\n",
    "**Origem dos dados:**\n",
    "- Arquivo: `D:\\Projetos\\Jornada_financas_pessoais\\data\\source\\Controle de A√ß√µes e FII*.xlsx`\n",
    "\n",
    "**Destino:**\n",
    "- Caminho Delta: `D:\\Projetos\\Jornada_financas_pessoais\\data\\delta\\bronze\\`\n",
    "- Tabela Delta: `bronze.raw_controleativo`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6354138",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566392d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_config import init_spark\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f65c5",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7e0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Spark 3.5.7 iniciado com Hive local persistente!\n",
      "üìÅ Warehouse: D:/Projetos/DataLake/spark-warehouse\n",
      "üìÅ Metastore: D:/Projetos/DataLake/metastore_db\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark(\"Leitura de arquivo de formato excel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e416b",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2006d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho do diret√≥rio dos arquivos de origem\n",
    "source_path = \"D:/Projetos/Jornada_financas_pessoais/data/source\"\n",
    "\n",
    "# Define caminhos locais onde ser√£o armazenadas as tabelas Delta\n",
    "base_bronze_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/bronze\"\n",
    "\n",
    "# Define o caminho da tabela Delta Source\n",
    "delta_path_controleativo = f\"{base_bronze_path}/raw_controleativo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd4d63",
   "metadata": {},
   "source": [
    "## Read Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8a88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos Excel encontrados: 1\n",
      "  - Controle de A√ß√µes e FII - Taynara.xlsx\n",
      "\n",
      "Processando: Controle de A√ß√µes e FII - Taynara.xlsx\n",
      "  ‚úì 63 registros lidos\n"
     ]
    }
   ],
   "source": [
    "# Lista todos os arquivos Excel que come√ßam com \"Controle de A√ß√µes e FII\"\n",
    "file_list = glob.glob(f'{source_path}/Controle de A√ß√µes e FII*.xlsx')\n",
    "\n",
    "print(f\"Arquivos Excel encontrados: {len(file_list)}\")\n",
    "for f in file_list:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# L√™ todos os arquivos Excel e adiciona coluna com nome do arquivo\n",
    "dfs_list = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    print(f\"\\nProcessando: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # L√™ apenas a aba \"FII\"\n",
    "    # header=0 (padr√£o) usa a primeira linha como nome das colunas\n",
    "    df_temp = pd.read_excel(\n",
    "        file_path,\n",
    "        sheet_name='FII',\n",
    "        engine='openpyxl',\n",
    "        header=0,  # Primeira linha (√≠ndice 0) = cabe√ßalho (PADR√ÉO)\n",
    "        dtype=str  # For√ßa todas as colunas como string\n",
    "    )\n",
    "    \n",
    "    # Faz o rename das colunas para casar com a tabela Delta\n",
    "    df_temp.rename(columns={\n",
    "        \"DATA\": \"data\",\n",
    "        \"PAPEL\": \"papel\",\n",
    "        \"OP\": \"op\",\n",
    "        \"QTD\": \"qtd\",\n",
    "        \"PRE√áO\": \"preco\",\n",
    "        \"CUS.T.\": \"custo_total\",\n",
    "        \"TOTAL OP\": \"total_op\",\n",
    "        \"RAT.\": \"rateio\",\n",
    "        \"V. LIQUIDO\": \"v_liquido\",\n",
    "        \"ESTOQUE\": \"estoque\",\n",
    "        \"PMEDIO\": \"pmedio\",\n",
    "        \"GAN/PER\": \"gan_per\",\n",
    "        \"IR M√äS\": \"ir_mes\",\n",
    "        \"M√äS REF.\": \"mes_ref\",\n",
    "        \"VENDAS/M√äS\": \"vendas_mes\",\n",
    "        \"CPF\": \"cpf\",\n",
    "        \"COTISTA\": \"cotista\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Adiciona coluna com nome do arquivo (apenas o nome, sem path)\n",
    "    df_temp['arquivo_origem'] = os.path.basename(file_path)\n",
    "    \n",
    "    dfs_list.append(df_temp)\n",
    "    print(f\"  ‚úì {len(df_temp)} registros lidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e43ab",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52548672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 registros lidos\n"
     ]
    }
   ],
   "source": [
    "# Concatena todos os DataFrames em um s√≥\n",
    "df_controleativo_pd = pd.concat(dfs_list, ignore_index=True)\n",
    "\n",
    "# Converte o DataFrame pandas para Spark\n",
    "df_controleativo = spark.createDataFrame(df_controleativo_pd)\n",
    "\n",
    "# For√ßa todas as colunas para STRING\n",
    "df_controleativo = df_controleativo.select(\n",
    "    [col(c).cast(\"string\").alias(c) for c in df_controleativo.columns]\n",
    ")\n",
    "\n",
    "print(df_controleativo.count(), \"registros lidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfcdb0",
   "metadata": {},
   "source": [
    "## Save Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66820de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] DataFrame gravado no Delta Lake em: D:/Projetos/Jornada_financas_pessoais/data/delta/bronze/raw_controleativo\n"
     ]
    }
   ],
   "source": [
    "# Grava em formato Delta\n",
    "(\n",
    "    df_controleativo.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"false\")\n",
    "    .save(delta_path_controleativo)\n",
    ")\n",
    "\n",
    "print(f\"[SUCESSO] DataFrame gravado no Delta Lake em: {delta_path_controleativo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650caec",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176a34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra a SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jornada-financas-pessoais-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
