{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98566ed5",
   "metadata": {},
   "source": [
    "# Carga Silver - Stage Controle Ativo\n",
    "\n",
    "Este notebook realiza a carga na silver controle ativo (stg_controle_ativo) a partir dos dados da tabela bronze controle ativo (raw_controleativo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a30a93",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85382964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DecimalType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989bb2d",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44df494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Spark 3.5.7 iniciado com metastore persistente!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializa uma SparkSession com metastore persistente\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Leitura e Transformação Delta Table\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"D:/Projetos/DataLake/spark-warehouse\")\n",
    "    .config(\n",
    "        \"javax.jdo.option.ConnectionURL\",\n",
    "        \"jdbc:derby:;databaseName=D:/Projetos/DataLake/metastore_db;create=true\"\n",
    "    )\n",
    "    .enableHiveSupport()\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"\\n✅ Spark {spark.version} iniciado com metastore persistente!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b132a8f",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf9a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define caminhos locais onde serão armazenadas as tabelas Delta\n",
    "base_bronze_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/bronze\"\n",
    "base_silver_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/silver\"\n",
    "\n",
    "# Define o caminho da tabela Delta Source\n",
    "delta_path_controleativo = f\"{base_bronze_path}/raw_controleativo\"\n",
    "\n",
    "# Define o caminho para salvar a tabela Delta transformada\n",
    "delta_path_controle_ativo = f\"{base_silver_path}/stg_controle_ativo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134635a",
   "metadata": {},
   "source": [
    "## Read Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da89e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] Leitura da tabela Delta em: D:/Projetos/Jornada_financas_pessoais/data/delta/bronze/raw_controleativo\n",
      "Total de registros: 63\n"
     ]
    }
   ],
   "source": [
    "# Lendo a tabela Delta no DataFrame do PySpark\n",
    "df_bronze = spark.read.format(\"delta\").load(delta_path_controleativo)\n",
    "\n",
    "print(f\"[SUCESSO] Leitura da tabela Delta em: {delta_path_controleativo}\")\n",
    "print(f\"Total de registros: {df_bronze.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ea37b",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1c8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter valores decimais para DECIMAL\n",
    "def parse_decimal(column_name):\n",
    "    return F.col(column_name).cast(DecimalType(11, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a35e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações de dados\n",
    "df_silver = df_bronze.select(\n",
    "    F.to_date(F.trim(F.col(\"data\")), \"yyyy-MM-dd HH:mm:ss\").alias(\"dt_operacao\"),\n",
    "    F.upper(F.trim(F.col(\"papel\"))).alias(\"cd_ativo\"),\n",
    "    F.upper(F.trim(F.col(\"op\"))).alias(\"cd_tipo_operacao\"),\n",
    "    F.when(F.trim(F.col(\"qtd\")).isNotNull() & (F.trim(F.col(\"qtd\")) != \"\"), \n",
    "           F.trim(F.col(\"qtd\")).cast(IntegerType()))\n",
    "     .otherwise(F.lit(0)).alias(\"qt_operacao\"),\n",
    "    parse_decimal(\"preco\").alias(\"vl_preco_ativo\"),\n",
    "    parse_decimal(\"custo_total\").alias(\"vl_custo_total\"),\n",
    "    parse_decimal(\"total_op\").alias(\"vl_total_operacao\"),\n",
    "    parse_decimal(\"rateio\").alias(\"vl_rateio\"),\n",
    "    parse_decimal(\"v_liquido\").alias(\"vl_liquido\"),\n",
    "    F.when(F.trim(F.col(\"estoque\")).isNotNull() & (F.trim(F.col(\"estoque\")) != \"\"), \n",
    "           F.trim(F.col(\"estoque\")).cast(IntegerType()))\n",
    "     .otherwise(F.lit(0)).alias(\"qt_estoque\"),\n",
    "    parse_decimal(\"pmedio\").alias(\"vl_pmedio\"),\n",
    "    parse_decimal(\"gan_per\").alias(\"vl_ganho_perda\"),\n",
    "    parse_decimal(\"ir_mes\").alias(\"ir_mes\"),\n",
    "    F.date_format(F.to_date(F.trim(F.col(\"data\")), \"yyyy-MM-dd HH:mm:ss\"), \"yyyy-MM\").alias(\"mes_referencia\"),\n",
    "    parse_decimal(\"vendas_mes\").alias(\"vl_vendas_mes\"),\n",
    "    F.regexp_replace(F.trim(F.col(\"cpf\")), r\"[^\\d]\", \"\").alias(\"cpf\"),\n",
    "    F.trim(F.col(\"cotista\")).alias(\"cotista\"),\n",
    "    F.trim(F.col(\"arquivo_origem\")).alias(\"arquivo_origem\"),\n",
    "\n",
    "    # Timestamp de inserção\n",
    "    F.current_timestamp().alias(\"ts_insercao\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774864a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] DataFrame transformado gravado no Delta Lake em: D:/Projetos/Jornada_financas_pessoais/data/delta/silver/stg_controle_ativo\n"
     ]
    }
   ],
   "source": [
    "# Salva o DataFrame transformado em formato Delta\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"false\").save(delta_path_controle_ativo)\n",
    "\n",
    "print(f\"[SUCESSO] DataFrame transformado gravado no Delta Lake em: {delta_path_controle_ativo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6696d6",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f9f93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra a SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jornada-financas-pessoais-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
