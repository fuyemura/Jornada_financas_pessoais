{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f8543e",
   "metadata": {},
   "source": [
    "# Carga Gold - Fato de Cota√ß√£o\n",
    "\n",
    "Este notebook realiza a carga da fato de cota√ß√£o (fato_cotacao) a partir dos dados da tabela staging de cota√ß√£o hist√≥rica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31477c71",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7cfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_config import init_spark\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee3a7e",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dbd93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Spark 3.5.7 iniciado com Hive local persistente!\n",
      "üìÅ Warehouse: D:/Projetos/DataLake/spark-warehouse\n",
      "üìÅ Metastore: D:/Projetos/DataLake/metastore_db\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark(\"Carga fato cota√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d46f1",
   "metadata": {},
   "source": [
    "## Define Delta Table Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea17242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define caminhos locais onde ser√£o armazenadas as tabelas Delta\n",
    "base_silver_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/silver\"\n",
    "base_gold_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/gold\"\n",
    "\n",
    "# Define caminhos das tabelas Delta\n",
    "delta_path_cotacao_historica = f\"{base_silver_path}/stg_cotacao_historica\"\n",
    "delta_path_dim_ativo = f\"{base_gold_path}/dim_ativo_financeiro\"\n",
    "delta_path_fato_cotacao = f\"{base_gold_path}/fato_cotacao\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe35b3f",
   "metadata": {},
   "source": [
    "## Read Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1662bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] Leitura da tabela staging em: D:/Projetos/Jornada_financas_pessoais/data/delta/silver/stg_cotacao_historica\n",
      "Total de registros: 2900062\n",
      "[SUCESSO] Leitura da tabela dimens√£o em: D:/Projetos/Jornada_financas_pessoais/data/delta/gold/dim_ativo_financeiro\n",
      "Total de registros: 3201\n"
     ]
    }
   ],
   "source": [
    "# L√™ a tabela staging de cota√ß√£o hist√≥rica\n",
    "df_stg_cotacao_historica = spark.read.format(\"delta\").load(delta_path_cotacao_historica)\n",
    "\n",
    "print(f\"[SUCESSO] Leitura da tabela staging em: {delta_path_cotacao_historica}\")\n",
    "print(f\"Total de registros: {df_stg_cotacao_historica.count()}\")\n",
    "\n",
    "df_dim_ativo = spark.read.format(\"delta\").load(delta_path_dim_ativo)\n",
    "\n",
    "print(f\"[SUCESSO] Leitura da tabela dimens√£o em: {delta_path_dim_ativo}\")\n",
    "print(f\"Total de registros: {df_dim_ativo.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9662ea8",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71db4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra apenas registros com tp_mercado = '10'\n",
    "df_stg_cotacao_historica = df_stg_cotacao_historica.filter(F.col(\"tp_mercado\") == \"010\")\n",
    "\n",
    "# Join LEFT (mant√©m todas as cota√ß√µes mesmo sem correspond√™ncia na dimens√£o)\n",
    "df_joined = (\n",
    "    df_stg_cotacao_historica.alias(\"stg\")\n",
    "    .join(\n",
    "        df_dim_ativo.alias(\"dim\"),\n",
    "        F.col(\"stg.cd_negociacao\") == F.col(\"dim.cd_ativo\"),\n",
    "        \"left\"  # mant√©m as linhas da stg mesmo se n√£o achar na dimens√£o\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tratamento da chave surrogate faltante (usa -1)\n",
    "df_fato_cotacao = (\n",
    "    df_joined.select(\n",
    "        F.col(\"stg.dt_pregao\"),\n",
    "        F.when(F.col(\"sk_ativo\").isNull(), F.lit(\"-1\")).otherwise(F.col(\"sk_ativo\")).alias(\"sk_ativo\"),\n",
    "        F.col(\"vl_abertura\"),\n",
    "        F.col(\"vl_minimo\"),\n",
    "        F.col(\"vl_maximo\"),\n",
    "        F.col(\"vl_medio\"),\n",
    "        F.col(\"vl_ultimo_negocio\"),\n",
    "        F.col(\"qt_negocios_efetuados\").alias(\"qt_negocio\"),\n",
    "        F.col(\"qt_total_titulos\").alias(\"qt_titulo\"),\n",
    "        F.col(\"vl_total_titulos\").alias(\"vl_volume\"),\n",
    "        F.current_timestamp().alias(\"ts_insercao\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1c80e",
   "metadata": {},
   "source": [
    "## Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a89ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Carregando 309457 registros de 231 datas\n",
      "‚úÖ Deletados dados de 231 datas\n",
      "‚úÖ Inseridos 309457 registros\n",
      "‚úÖ Carga e otimiza√ß√£o conclu√≠das!\n"
     ]
    }
   ],
   "source": [
    "# Obter datas a reprocessar\n",
    "datas = [row.dt_pregao for row in df_fato_cotacao.select(\"dt_pregao\").distinct().collect()]\n",
    "\n",
    "print(f\"üìä Carregando {df_fato_cotacao.count()} registros de {len(datas)} datas\")\n",
    "\n",
    "# Processar\n",
    "if DeltaTable.isDeltaTable(spark, delta_path_fato_cotacao):\n",
    "    deltaTable = DeltaTable.forPath(spark, delta_path_fato_cotacao)\n",
    "    \n",
    "    # DELETE per√≠odos\n",
    "    if datas:\n",
    "        df_datas = spark.createDataFrame([(d,) for d in datas], [\"dt_pregao\"])\n",
    "        deltaTable.alias(\"destino\").merge(\n",
    "            df_datas.alias(\"datas\"),\n",
    "            \"destino.dt_pregao = datas.dt_pregao\"\n",
    "        ).whenMatchedDelete().execute()\n",
    "        print(f\"‚úÖ Deletados dados de {len(datas)} datas\")\n",
    "    \n",
    "    # INSERT\n",
    "    df_fato_cotacao.write.format(\"delta\").mode(\"append\").save(delta_path_fato_cotacao)\n",
    "    print(f\"‚úÖ Inseridos {df_fato_cotacao.count()} registros\")\n",
    "    \n",
    "else:\n",
    "    # Primeira carga\n",
    "    df_fato_cotacao.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"false\").save(delta_path_fato_cotacao)\n",
    "    print(f\"‚úÖ Tabela criada com {df_fato_cotacao.count()} registros\")\n",
    "\n",
    "# OPTIMIZE\n",
    "DeltaTable.forPath(spark, delta_path_fato_cotacao).optimize().executeCompaction()\n",
    "print(\"‚úÖ Carga e otimiza√ß√£o conclu√≠das!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b371b",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c30772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra a SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jornada-financas-pessoais-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
