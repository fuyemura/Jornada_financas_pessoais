{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475f2966",
   "metadata": {},
   "source": [
    "# Ingest√£o Bronze - Cadastro de Cliente\n",
    "\n",
    "Este notebook realiza a ingest√£o de um arquivo Excel contendo o cadastro de clientes\n",
    "e grava os dados em formato Delta na camada **Bronze**.\n",
    "\n",
    "**Origem dos dados:**\n",
    "- Arquivo: `D:\\Projetos\\Jornada_financas_pessoais\\data\\source\\cadastro_cliente.xlsx`\n",
    "\n",
    "**Destino:**\n",
    "- Caminho Delta: `D:\\Projetos\\Jornada_financas_pessoais\\data\\delta\\bronze\\`\n",
    "- Tabela Delta: `bronze.raw_cadcliente`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6354138",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566392d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_config import init_spark\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f65c5",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7e0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Spark 3.5.7 iniciado com Hive local persistente!\n",
      "üìÅ Warehouse: D:/Projetos/DataLake/spark-warehouse\n",
      "üìÅ Metastore: D:/Projetos/DataLake/metastore_db\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark(\"Leitura de arquivo de formato excel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e416b",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2006d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho do diret√≥rio dos arquivos de origem\n",
    "source_path = \"D:/Projetos/Jornada_financas_pessoais/data/source\"\n",
    "\n",
    "source_file_path = f'{source_path}/Cadastro_Cliente.xlsx'\n",
    "\n",
    "source_file_name = os.path.basename(source_file_path)\n",
    "\n",
    "# Define caminhos locais onde ser√£o armazenadas as tabelas Delta\n",
    "base_bronze_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/bronze\"\n",
    "\n",
    "# Define o caminho da tabela Delta Source\n",
    "delta_path_cadcliente = f\"{base_bronze_path}/raw_cadcliente\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd4d63",
   "metadata": {},
   "source": [
    "## Read Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8a88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 registros lidos\n"
     ]
    }
   ],
   "source": [
    "# L√™ o Excel com pandas\n",
    "df_cadcliente_pd = pd.read_excel(\n",
    "    source_file_path,\n",
    "    engine='openpyxl',\n",
    "    dtype=str  # For√ßa todas as colunas como string\n",
    ")\n",
    "\n",
    "# Adiciona o nome do arquivo como nova coluna\n",
    "df_cadcliente_pd['nome_arquivo'] = source_file_name\n",
    "\n",
    "# Renomeia a coluna DATA NASCIMENTO\n",
    "df_cadcliente_pd.rename(columns={'DATA NASCIMENTO': 'data_nascimento'}, inplace=True)\n",
    "\n",
    "# Converte para PySpark DataFrame\n",
    "df_cadcliente = spark.createDataFrame(df_cadcliente_pd)\n",
    "\n",
    "print(df_cadcliente.count(), \"registros lidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfcdb0",
   "metadata": {},
   "source": [
    "## Save Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66820de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] DataFrame gravado no Delta Lake em: D:/Projetos/Jornada_financas_pessoais/data/delta/bronze/raw_cadcliente\n"
     ]
    }
   ],
   "source": [
    "# Grava em formato Delta\n",
    "(\n",
    "    df_cadcliente.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"false\")\n",
    "    .save(delta_path_cadcliente)\n",
    ")\n",
    "\n",
    "print(f\"[SUCESSO] DataFrame gravado no Delta Lake em: {delta_path_cadcliente}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650caec",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176a34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra a SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jornada-financas-pessoais-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
