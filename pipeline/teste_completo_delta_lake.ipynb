{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45256d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Delta Lake - Teste Completo dos Principais Recursos\n",
    "VersÃ£o testada e funcionando!\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DELTA LAKE - TESTE COMPLETO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLakeCompleto\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.13:3.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"\\nâœ… Spark {spark.version} iniciado!\\n\")\n",
    "\n",
    "# Caminho da tabela\n",
    "caminho = \"/tmp/clientes_delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. CRIAR TABELA DELTA ==========\n",
    "print(\"ğŸ“ 1. CRIANDO TABELA DELTA\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "clientes = spark.createDataFrame([\n",
    "    (1, \"JoÃ£o Silva\", \"SP\", 5000.00, \"Ativo\"),\n",
    "    (2, \"Maria Santos\", \"RJ\", 7500.00, \"Ativo\"),\n",
    "    (3, \"Pedro Costa\", \"MG\", 4500.00, \"Ativo\"),\n",
    "    (4, \"Ana Souza\", \"SP\", 6000.00, \"Ativo\"),\n",
    "    (5, \"Carlos Lima\", \"RS\", 5500.00, \"Ativo\")\n",
    "], [\"id\", \"nome\", \"estado\", \"credito\", \"status\"])\n",
    "\n",
    "clientes.write.format(\"delta\").mode(\"overwrite\").save(caminho)\n",
    "print(\"âœ… Tabela criada com sucesso!\")\n",
    "print(f\"   LocalizaÃ§Ã£o: {caminho}\\n\")\n",
    "\n",
    "spark.read.format(\"delta\").load(caminho).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0475a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. LER DADOS ==========\n",
    "print(\"\\nğŸ“– 2. LENDO DADOS DA TABELA\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df = spark.read.format(\"delta\").load(caminho)\n",
    "print(f\"Total de clientes: {df.count()}\")\n",
    "print(f\"Clientes de SP: {df.filter(col('estado') == 'SP').count()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3. ADICIONAR NOVOS DADOS (APPEND) ==========\n",
    "print(\"â• 3. ADICIONANDO NOVOS CLIENTES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "novos_clientes = spark.createDataFrame([\n",
    "    (6, \"Beatriz Alves\", \"BA\", 6500.00, \"Ativo\"),\n",
    "    (7, \"Rafael Dias\", \"PE\", 5800.00, \"Ativo\")\n",
    "], [\"id\", \"nome\", \"estado\", \"credito\", \"status\"])\n",
    "\n",
    "novos_clientes.write.format(\"delta\").mode(\"append\").save(caminho)\n",
    "print(\"âœ… Novos clientes adicionados!\\n\")\n",
    "\n",
    "spark.read.format(\"delta\").load(caminho).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. ATUALIZAR DADOS (UPDATE) ==========\n",
    "print(\"\\nğŸ”„ 4. ATUALIZANDO DADOS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Aumentando crÃ©dito em 10% para clientes de SP...\")\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, caminho)\n",
    "\n",
    "delta_table.update(\n",
    "    condition = col(\"estado\") == \"SP\",\n",
    "    set = {\"credito\": col(\"credito\") * 1.10}\n",
    ")\n",
    "\n",
    "print(\"âœ… CrÃ©ditos atualizados!\\n\")\n",
    "spark.read.format(\"delta\").load(caminho).orderBy(\"id\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd165b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 5. DELETAR DADOS (DELETE) ==========\n",
    "print(\"\\nğŸ—‘ï¸  5. REMOVENDO DADOS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Removendo cliente com id = 3...\")\n",
    "\n",
    "delta_table.delete(condition = col(\"id\") == 3)\n",
    "\n",
    "print(\"âœ… Cliente removido!\\n\")\n",
    "spark.read.format(\"delta\").load(caminho).orderBy(\"id\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 6. MERGE (UPSERT) ==========\n",
    "print(\"\\nğŸ”€ 6. MERGE (UPSERT)\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Atualizando cliente 2 e inserindo cliente 8...\")\n",
    "\n",
    "dados_merge = spark.createDataFrame([\n",
    "    (2, \"Maria Santos Silva\", \"RJ\", 8000.00, \"Premium\"),  # Atualizar\n",
    "    (8, \"Fernando Rocha\", \"SC\", 7000.00, \"Ativo\")         # Inserir\n",
    "], [\"id\", \"nome\", \"estado\", \"credito\", \"status\"])\n",
    "\n",
    "delta_table.alias(\"target\").merge(\n",
    "    dados_merge.alias(\"source\"),\n",
    "    \"target.id = source.id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "\n",
    "print(\"âœ… MERGE executado!\")\n",
    "print(\"   - Cliente 2 atualizado (nome e crÃ©dito)\")\n",
    "print(\"   - Cliente 8 inserido\\n\")\n",
    "\n",
    "spark.read.format(\"delta\").load(caminho).orderBy(\"id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 7. HISTÃ“RICO DE VERSÃ•ES ==========\n",
    "print(\"\\nğŸ“œ 7. HISTÃ“RICO DE VERSÃ•ES (TIME TRAVEL)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "history = delta_table.history()\n",
    "print(\"Todas as operaÃ§Ãµes realizadas:\")\n",
    "history.select(\"version\", \"timestamp\", \"operation\", \"operationMetrics\") \\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ace5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== 8. TIME TRAVEL - VERSÃƒO ANTERIOR ==========\n",
    "print(\"\\nâ° 8. VIAJANDO NO TEMPO\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Voltando para a versÃ£o 0 (dados originais)...\\n\")\n",
    "\n",
    "df_v0 = spark.read \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"versionAsOf\", 0) \\\n",
    "    .load(caminho)\n",
    "\n",
    "print(\"Dados na versÃ£o 0:\")\n",
    "df_v0.show()\n",
    "\n",
    "print(\"ComparaÃ§Ã£o:\")\n",
    "print(f\"  VersÃ£o 0: {df_v0.count()} clientes\")\n",
    "print(f\"  VersÃ£o atual: {spark.read.format('delta').load(caminho).count()} clientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63162559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 9. FILTROS E CONSULTAS ==========\n",
    "print(\"\\nğŸ” 9. CONSULTAS E FILTROS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df_atual = spark.read.format(\"delta\").load(caminho)\n",
    "\n",
    "print(\"Clientes com crÃ©dito > 6000:\")\n",
    "df_atual.filter(col(\"credito\") > 6000).show()\n",
    "\n",
    "print(\"Clientes por estado:\")\n",
    "df_atual.groupBy(\"estado\").count().orderBy(\"estado\").show()\n",
    "\n",
    "print(\"Cliente com maior crÃ©dito:\")\n",
    "df_atual.orderBy(col(\"credito\").desc()).limit(1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RESUMO FINAL ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… TESTE COMPLETO CONCLUÃDO COM SUCESSO!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“Š OperaÃ§Ãµes testadas:\")\n",
    "print(\"  âœ“ CREATE - Criar tabela Delta\")\n",
    "print(\"  âœ“ READ - Ler dados\")\n",
    "print(\"  âœ“ APPEND - Adicionar registros\")\n",
    "print(\"  âœ“ UPDATE - Atualizar registros\")\n",
    "print(\"  âœ“ DELETE - Remover registros\")\n",
    "print(\"  âœ“ MERGE - Upsert (atualizar ou inserir)\")\n",
    "print(\"  âœ“ HISTORY - Ver histÃ³rico de versÃµes\")\n",
    "print(\"  âœ“ TIME TRAVEL - Acessar versÃµes anteriores\")\n",
    "print(\"  âœ“ QUERY - Filtros e consultas\")\n",
    "print(\"\\nğŸ’¡ Delta Lake estÃ¡ 100% funcional!\")\n",
    "print(f\"ğŸ“ Dados em: {caminho}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark.stop()\n",
    "print(\"\\nğŸ›‘ Spark encerrado.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
