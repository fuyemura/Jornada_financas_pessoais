{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f8543e",
   "metadata": {},
   "source": [
    "# Carga da Dimens√£o Cliente\n",
    "\n",
    "Este notebook realiza a carga da dimens√£o cliente (dim_cliente) a partir dos dados da tabela raw de cadastro de cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31477c71",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7cfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, sha2, coalesce\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee3a7e",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dbd93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Spark 3.5.7 iniciado com metastore persistente!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializa uma SparkSession com metastore persistente\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Carga Dimens√£o Cliente\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"D:/Projetos/DataLake/spark-warehouse\")\n",
    "    .config(\n",
    "        \"javax.jdo.option.ConnectionURL\",\n",
    "        \"jdbc:derby:;databaseName=D:/Projetos/DataLake/metastore_db;create=true\"\n",
    "    )\n",
    "    .enableHiveSupport()\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"\\n‚úÖ Spark {spark.version} iniciado com metastore persistente!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d46f1",
   "metadata": {},
   "source": [
    "## Define Delta Table Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea17242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define caminhos locais onde ser√£o armazenadas as tabelas Delta\n",
    "base_bronze_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/bronze\"\n",
    "base_gold_path = \"D:/Projetos/Jornada_financas_pessoais/data/delta/gold\"\n",
    "\n",
    "# Define caminhos das tabelas Delta\n",
    "delta_path_cadcliente = f\"{base_bronze_path}/raw_cadcliente\"\n",
    "delta_path_dim_cliente = f\"{base_gold_path}/dim_cliente\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe35b3f",
   "metadata": {},
   "source": [
    "## Read Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1662bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCESSO] Leitura da tabela staging em: D:/Projetos/Jornada_financas_pessoais/data/delta/bronze/raw_cadcliente\n",
      "Total de registros: 2\n"
     ]
    }
   ],
   "source": [
    "# L√™ a tabela bronze de cadastro de clientes\n",
    "df_raw_cadcliente = spark.read.format(\"delta\").load(delta_path_cadcliente)\n",
    "\n",
    "print(f\"[SUCESSO] Leitura da tabela staging em: {delta_path_cadcliente}\")\n",
    "print(f\"Total de registros: {df_raw_cadcliente.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9662ea8",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82424942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera chave surrogate e transforma os dados para dimens√£o cliente\n",
    "df_dim_cliente = df_raw_cadcliente.select(\n",
    "    # Gera surrogate key usando sha2 do CPF\n",
    "    sha2(col(\"cpf\"), 256).alias(\"sk_cliente\"),\n",
    "    col(\"cpf\").alias(\"cd_cpf_pessoa\"),\n",
    "    col(\"nome\").alias(\"nm_cliente\"),\n",
    "    col(\"data_nascimento\").cast(\"date\").alias(\"dt_nascimento\"),\n",
    "    \n",
    "    col(\"email\").alias(\"ds_email\"),\n",
    "    col(\"telefone\").alias(\"nr_telefone\")\n",
    ")\n",
    "\n",
    "# Remove duplicatas baseado no CPF (mant√©m o registro mais recente)\n",
    "df_dim_cliente = df_dim_cliente.dropDuplicates([\"cd_cpf_pessoa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1c80e",
   "metadata": {},
   "source": [
    "## Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2d70bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merge realizado com sucesso\n",
      "üÜï Inseridos: 2\n",
      "‚ôªÔ∏è Atualizados: 0\n"
     ]
    }
   ],
   "source": [
    "# Carrega a tabela Delta existente\n",
    "deltaTable = DeltaTable.forPath(spark, delta_path_dim_cliente)\n",
    "\n",
    "# Realiza o merge (upsert) na tabela Delta\n",
    "(\n",
    "    deltaTable.alias(\"target\")\n",
    "    .merge(\n",
    "        df_dim_cliente.alias(\"source\"),\n",
    "        \"target.cd_cpf_pessoa = source.cd_cpf_pessoa\"  # Merge por CPF (chave natural)\n",
    "    )\n",
    "    # Quando o registro j√° existe e h√° diferen√ßa nos campos relevantes ‚Üí atualiza\n",
    "    .whenMatchedUpdate(\n",
    "        condition=\"\"\"\n",
    "            coalesce(target.nm_cliente, '') != coalesce(source.nm_cliente, '') OR \n",
    "            coalesce(target.dt_nascimento, '') != coalesce(source.dt_nascimento, '') OR \n",
    "            coalesce(target.ds_email, '') != coalesce(source.ds_email, '') OR \n",
    "            coalesce(target.nr_telefone, '') != coalesce(source.nr_telefone, '')\n",
    "        \"\"\",\n",
    "        set={\n",
    "            \"nm_cliente\": \"source.nm_cliente\",\n",
    "            \"dt_nascimento\": \"source.dt_nascimento\",\n",
    "            \"ds_email\": \"source.ds_email\",\n",
    "            \"nr_telefone\": \"source.nr_telefone\",\n",
    "            \"ts_atualizacao\": \"current_timestamp()\"  # Atualiza timestamp no update\n",
    "        }\n",
    "    )\n",
    "    # Quando o registro n√£o existe ‚Üí insere novo\n",
    "    .whenNotMatchedInsert(values={\n",
    "        \"sk_cliente\": \"source.sk_cliente\",\n",
    "        \"cd_cpf_pessoa\": \"source.cd_cpf_pessoa\",\n",
    "        \"nm_cliente\": \"source.nm_cliente\",\n",
    "        \"dt_nascimento\": \"source.dt_nascimento\",\n",
    "        \"ds_email\": \"source.ds_email\",\n",
    "        \"nr_telefone\": \"source.nr_telefone\",\n",
    "        \"ts_insercao\": \"current_timestamp()\",  # Data/hora da inser√ß√£o\n",
    "        \"ts_atualizacao\": \"null\"               # Ainda n√£o foi atualizado\n",
    "    })\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "# üìä Obt√©m m√©tricas do √∫ltimo merge\n",
    "last_operation = deltaTable.history(1).select(\"operationMetrics\").collect()[0][0]\n",
    "inserted = int(last_operation.get(\"numTargetRowsInserted\", 0))\n",
    "updated = int(last_operation.get(\"numTargetRowsUpdated\", 0))\n",
    "\n",
    "print(f\"‚úÖ Merge realizado com sucesso\")\n",
    "print(f\"üÜï Inseridos: {inserted}\")\n",
    "print(f\"‚ôªÔ∏è Atualizados: {updated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b371b",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c30772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra a SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jornada-financas-pessoais-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
